# REACT: Two Datasets for Analyzing Both Human Reactions and Evaluative Feedback to Robots Over Time

Recent work in Human-Robot Interaction (HRI) has shown that robots can leverage implicit communicative signals from users to understand how they are being perceived during interactions. For example, these signals can be gaze patterns, facial expressions, or body motions that reflect internal human states. To facilitate future research in this direction, we contribute the REACT database, a collection of two datasets of human-robot interactions that display usersâ€™ natural reactions to robots during a collaborative game and a photography scenario. Further, we analyze the datasets to show that interaction history is an important factor that can influence human reactions to robots. As a result, we believe that future models for interpreting implicit feedback in HRI should explicitly account for this history. REACT opens up doors to this possibility in the future.

We contribute the Reactions and EvaluAtive feedbaCk over Time (REACT) database. REACT consists of two datasets that contain observations of humans, robots and task-related data during human-robot interactions. The dataset is organized as follows:

* [REACT-Nao](react-nao)
  * [data](react-nao/data/REACT-Nao_Data.md)
  * [data_processing](react-nao/data_processing)
  * [example_analysis](react-nao/example_analysis) 
* [REACT-Shutter](react-shutter)
  * [data](react-shutter/data/REACT-Shutter_Data.md)
  * [data_processing](react-shutter/data_processing/react-shutter_dataprocessing.md)
  * [example_analysis](react-shutter/example_analysis/react-shutter_paperanalysis.ipynb) 

Please see our paper for additional details.
